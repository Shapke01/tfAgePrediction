{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "assert tf.config.list_physical_devices('GPU')\n",
    "assert tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "trainDatagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "    #rotation_range= 40,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    #horizontal_flip=True\n",
    ")\n",
    "testDatagen = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"Gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15584 images belonging to 2 classes.\n",
      "Found 5453 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainData = trainDatagen.flow_from_directory(\n",
    "    directory=category+\"/train/\", \n",
    "    class_mode=\"binary\",\n",
    "    target_size=(200,200),\n",
    "    batch_size=32)\n",
    "    \n",
    "testData = testDatagen.flow_from_directory(\n",
    "    directory=category+\"/test/\",\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(200,200),\n",
    "    batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy, binary_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(\n",
    "        kernel_size = 4,\n",
    "        filters=64,\n",
    "        activation = \"relu\",\n",
    "        input_shape = (200, 200, 3)),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10, 3, activation = \"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10, 3, activation = \"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10, 3, activation = \"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = binary_crossentropy,\n",
    "    optimizer = Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 197, 197, 64)      3136      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 10)        5770      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 10)        910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 10)        910       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4410)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4411      \n",
      "=================================================================\n",
      "Total params: 15,137\n",
      "Trainable params: 15,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "487/487 [==============================] - 240s 447ms/step - loss: 0.4371 - accuracy: 0.7904 - val_loss: 0.3282 - val_accuracy: 0.8582\n",
      "Epoch 2/1000\n",
      "487/487 [==============================] - 131s 269ms/step - loss: 0.3038 - accuracy: 0.8780 - val_loss: 0.2890 - val_accuracy: 0.8872\n",
      "Epoch 3/1000\n",
      "487/487 [==============================] - 148s 303ms/step - loss: 0.2763 - accuracy: 0.8878 - val_loss: 0.2780 - val_accuracy: 0.8878\n",
      "Epoch 4/1000\n",
      "487/487 [==============================] - 139s 284ms/step - loss: 0.2517 - accuracy: 0.8975 - val_loss: 0.2957 - val_accuracy: 0.8834\n",
      "Epoch 5/1000\n",
      "487/487 [==============================] - 139s 286ms/step - loss: 0.2326 - accuracy: 0.9094 - val_loss: 0.2438 - val_accuracy: 0.9087\n",
      "Epoch 6/1000\n",
      "487/487 [==============================] - 143s 293ms/step - loss: 0.2202 - accuracy: 0.9162 - val_loss: 0.2932 - val_accuracy: 0.8802\n",
      "Epoch 7/1000\n",
      "487/487 [==============================] - 143s 293ms/step - loss: 0.2079 - accuracy: 0.9215 - val_loss: 0.2702 - val_accuracy: 0.8913\n",
      "Epoch 8/1000\n",
      "487/487 [==============================] - 139s 286ms/step - loss: 0.1964 - accuracy: 0.9265 - val_loss: 0.2413 - val_accuracy: 0.9083\n",
      "Epoch 9/1000\n",
      "487/487 [==============================] - 147s 302ms/step - loss: 0.1894 - accuracy: 0.9279 - val_loss: 0.2495 - val_accuracy: 0.9100\n",
      "Epoch 10/1000\n",
      "487/487 [==============================] - 128s 262ms/step - loss: 0.1784 - accuracy: 0.9324 - val_loss: 0.2454 - val_accuracy: 0.9103\n",
      "Epoch 11/1000\n",
      "487/487 [==============================] - 146s 300ms/step - loss: 0.1717 - accuracy: 0.9372 - val_loss: 0.2441 - val_accuracy: 0.9078\n",
      "Epoch 12/1000\n",
      "487/487 [==============================] - 146s 300ms/step - loss: 0.1649 - accuracy: 0.9402 - val_loss: 0.2612 - val_accuracy: 0.9067\n",
      "Epoch 13/1000\n",
      "487/487 [==============================] - 146s 301ms/step - loss: 0.1592 - accuracy: 0.9421 - val_loss: 0.2642 - val_accuracy: 0.9090\n",
      "Epoch 14/1000\n",
      "487/487 [==============================] - 146s 300ms/step - loss: 0.1538 - accuracy: 0.9428 - val_loss: 0.2544 - val_accuracy: 0.9061\n",
      "Epoch 15/1000\n",
      "487/487 [==============================] - 146s 300ms/step - loss: 0.1494 - accuracy: 0.9455 - val_loss: 0.2543 - val_accuracy: 0.9065\n",
      "Epoch 16/1000\n",
      "487/487 [==============================] - 142s 292ms/step - loss: 0.1406 - accuracy: 0.9512 - val_loss: 0.2961 - val_accuracy: 0.9024\n",
      "Epoch 17/1000\n",
      "487/487 [==============================] - 146s 299ms/step - loss: 0.1362 - accuracy: 0.9503 - val_loss: 0.2911 - val_accuracy: 0.9052\n",
      "Epoch 18/1000\n",
      "487/487 [==============================] - 142s 292ms/step - loss: 0.1314 - accuracy: 0.9530 - val_loss: 0.2948 - val_accuracy: 0.9094\n",
      "Epoch 19/1000\n",
      "487/487 [==============================] - 146s 299ms/step - loss: 0.1243 - accuracy: 0.9564 - val_loss: 0.2863 - val_accuracy: 0.8997\n",
      "Epoch 20/1000\n",
      "487/487 [==============================] - 145s 298ms/step - loss: 0.1218 - accuracy: 0.9580 - val_loss: 0.2970 - val_accuracy: 0.8995\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    trainData,\n",
    "    steps_per_epoch = len(trainData),\n",
    "    validation_data = testData,\n",
    "    validation_steps = len(testData),\n",
    "    epochs=1000,\n",
    "    callbacks = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: myModel3\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"myModel3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "def predict(model, path):\n",
    "    img = load_img(path, target_size=(200, 200))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    print(model.predict(img_array))\n",
    "\n",
    "predict(model, \"ja.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20d4b83e0c8b3730b580c42434163d64f4b735d580303a8fade7c849d4d29eba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
